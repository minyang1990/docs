# 【原创长文】不要被官方参数骗了，各大模型实际长文输出能力测试研究【长期更新】 - 搞七捻三 - LINUX DO
[【原创长文】不要被官方参数骗了，各大模型实际长文输出能力测试研究【长期更新】 - 搞七捻三 - LINUX DO](https://linux.do/t/topic/585363/5) 

  【原创长文】不要被官方参数骗了，各大模型实际长文输出能力测试研究【长期更新】 - 搞七捻三 - LINUX DO                                                

[跳到主要内容](#main-container)

 [![](https://cdn.ldstatic.com/original/3X/9/d/9dd49731091ce8656e94433a26a3ef36062b3994.png)](/) 

[【原创长文】不要被官方参数骗了，各大模型实际长文输出能力测试研究【长期更新】](/t/topic/585363)


===========================================================

[搞七捻三](/c/gossip/11)

[纯水](/tag/纯水)

,[人工智能](/tag/人工智能)

,[OpenAI](/tag/openai)

*   ​
*   ​

*    ![](https://cdn.linux.do/letter_avatar/niyan2025/96/5_d44a9b381edc88181525e3c8350177ca.png) 

*   [话题](/latest "所有话题")
*   [我的帖子](/u/niyan2025/activity/drafts "我的未发布草稿")
*   [关于](/about "关于此网站的更多详细信息")
*   [即将到来的活动](/upcoming-events "即将到来的活动")
*   更多

外部链接

*   [Status](https://status.linux.do)
*   [T-Shirt](https://item.taobao.com/item.htm?id=910907382401)
*   [Connect](https://connect.linux.do)
*   [Webmail](https://webmail.linux.do)
*   [Channel](https://t.me/linux_do_channel)
*   [Telegram](https://t.me/ja_netfilter_group)

类别

*   [开发调优](/c/develop/4 "此版块包含开发、测试、调试、部署、优化、安全等方面的内容")
*   [资源荟萃](/c/resource/14 "包括软件分享、开源仓库、视频课程、书籍等分享")
*   [文档共建](/c/wiki/42 "佬友化身翰林学士，一起来编书了。")
*   [跳蚤市场](/c/trade/10 "交易相关的版块，包含实体和虚拟物品供求、拼车等等")
*   [非我莫属](/c/job/27 "学成文武艺，货与帝王家。招聘/求职分类，只能发此类信息。")
*   [读书成诗](/c/reading/32 "跟着佬友们一起在论坛读完一本书是什么体验？")
*   [扬帆起航](/c/startup/46 "扬帆起航，目标是星辰大海！")
*   [前沿快讯](/c/news/34 "前沿快讯，不出门能知天下事。")
*   [网络记忆](/c/feeds/92 "网络是有记忆的，确信！")
*   [福利羊毛](/c/welfare/36 "正经人谁花那个钱啊～ 此版块供羊毛、抽奖等福利使用。")
*   [搞七捻三](/c/gossip/11 "闲聊吹水的板块。不得讨论政治、色情等违规内容。")
*   [运营反馈](/c/feedback/2 "有关此站点、其组织、运作方式以及如何改进的讨论。")
*   [深海幽域](/c/muted/45 "冰山下的深海。帖子不会上信息流、不会被论坛搜索。")
*   [所有类别](/categories)

标签

*   [人工智能](/tag/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD)
*   [公告](/tag/%E5%85%AC%E5%91%8A)
*   [快问快答](/tag/%E5%BF%AB%E9%97%AE%E5%BF%AB%E7%AD%94)
*   [抽奖](/tag/%E6%8A%BD%E5%A5%96)
*   [精华神帖](/tag/%E7%B2%BE%E5%8D%8E%E7%A5%9E%E5%B8%96)
*   [所有标签](/tags)

消息

*   [收件箱](/u/niyan2025/messages)

*   [我的消息串](/chat/threads "我的消息串")

频道

*   [常规频道](/chat/c/general/2 "🈲 禁止在聊天频道里发送 打卡 等无意义信息，被举报会喜提 禁言1小时 。")

直接消息

*    [![](https://cdn.linux.do/user_avatar/linux.do/huan/48/293194_2.png)  焕昭君](/chat/c/%E7%84%95%E6%98%AD%E5%90%9B/43057 "与 焕昭君 聊天") 
*    [![](https://cdn.linux.do/user_avatar/linux.do/xronus/48/130867_2.png)  Anivix](/chat/c/anivix/32458 "与 Anivix 聊天") 

聊天

Default

​ ​ ​

**真诚**、**友善**、**团结**、**专业**，共建你我引以为荣之社区。[《常见问题解答》](/faq)

[【原创长文】不要被官方参数骗了，各大模型实际长文输出能力测试研究【长期更新】](/t/topic/585363)


===========================================================

[搞七捻三](/c/gossip/11)

[纯水](/tag/纯水)

,[人工智能](/tag/人工智能)

,[OpenAI](/tag/openai)

您已选择 **0** 个帖子。

全选

取消选择

​

[4月 21 日](/t/topic/585363/1 "跳到第一个帖子")

5 / 25

4月 22 日

[43 分钟](/t/topic/585363/26)

​

[![](https://cdn.linux.do/user_avatar/linux.do/dwqxq1/96/412659_2.png)
](/u/dwqxq1)

[dwqxq1](/u/dwqxq1)

活跃用户

18

[3 小时](/t/topic/585363?u=niyan2025 "发布日期")

**省流版**：只有O3 Deep research，2.5pro，2.5flash和3.7有真正稳定的20k以上长文输出能力

[](#p-5330324-h-1)定义
--------------------

**什么叫字数思想钢印**：一个比喻，形容实际输出字数远低于官方公布的最大输出token数  
这个思想钢印可能是加在系统提示词里的，并不是底模本身能力的限制，完全是人为后加的限制和阉割  
例如o3 Deep research最大输出60k，o3输出字数就只有2k，差了30倍  
**什么叫长文**：我定义为2k字以上的文字，最好10~20k以上  
**有固定字数的长文**：照抄/翻译，输入与输出token基本对等的  
**没有固定字数的长文**：提问，小说，写作，研究  
人为指定字数不算固定字数，因为大多数模型不会遵从字数多的指令，模型对自己写了多少字的统计误差也经常差出几倍（俗称不识数）

[](#p-5330324-h-2)长文的要求
-----------------------

**①理论最终输出字数多**：大模型的模型输出一般只宣传输出token数，包含思考token数和最终输出token数。有两种情况  
Ⓐ思考与最终token数固定分配的：例如2.5flash思考固定24k，最终输出固定40k，即便不思考，最终输出字数也只能40k  
Ⓑ思考与最终token数动态分类的：思考用的少，最终字数就可以多，例如3.7-thinking动态分配64k，2.5pro动态分配64k  
**②实际输出字数多**  
**③长文阅读能力随上下文增加衰减慢**

[](#p-5330324-h-3)长文的用途
-----------------------

**翻译**：一本书一般一章就是1万多字。  
如果碰到2k实际输出的模型，一本10万字的 书要翻译50次才能翻译完，麻烦，而且容易马虎造成翻译重复，漏翻译  
虽然也可以分开翻译  
**长代码**：一般每行10tokens，20k输出=2000行  
**总结**：一般的书籍浓缩（听书）是30分钟1w字（得到）或60分钟2w字（樊登/帆书）  
**研究/论文**：O3 Deep research的一篇研究报告的标准长度也是一万多字  
**小说**：每个章节2k~4k字  
**其他写作**：

[](#p-5330324-h-4)测试标准
----------------------

以下都是数值都是实际输出平均上限  
单位是汉字  
测试图标说明：  
![](https://cdn.linux.do/images/emoji/twemoji/white_check_mark.png?v=14)
\=照抄/翻译能用基本满理论最大输出，小说/研究能用满一半理论上限  
![](https://cdn.linux.do/images/emoji/twemoji/yellow_circle.png?v=14)
\=输出较多，但用不满  
![](https://cdn.linux.do/images/emoji/twemoji/cross_mark.png?v=14)
\=输出2k左右，或者拒绝输出

[](#p-5330324-h-5)有严格字数思想钢印的（照抄/翻译和自由发挥字都少）
-------------------------------------------

#### [](#p-5330324-gpt-6)GPT

字数统计准确率：25%，就是他说他写了1万字，实际可能只有2500字  
**o3 Deep research**：![](https://cdn.linux.do/images/emoji/twemoji/white_check_mark.png?v=14)
chat研究60k  
格式较固定，例如8节×4小节×600字  
无api  
**o3**：api理论![](https://cdn.linux.do/images/emoji/twemoji/red_question_mark.png?v=14)
k，![](https://cdn.linux.do/images/emoji/twemoji/cross_mark.png?v=14)
实际api照抄/翻译/小说都是2k，![](https://cdn.linux.do/images/emoji/twemoji/cross_mark.png?v=14)
代码4k(400行)  
**o4-mini**：api理论![](https://cdn.linux.do/images/emoji/twemoji/red_question_mark.png?v=14)
k，![](https://cdn.linux.do/images/emoji/twemoji/cross_mark.png?v=14)
api照抄2k，![](https://cdn.linux.do/images/emoji/twemoji/cross_mark.png?v=14)
翻译4k(会缩写)，![](https://cdn.linux.do/images/emoji/twemoji/cross_mark.png?v=14)
小说2k  
o4-mini的长文能力是显著低于o3-mini的，体现之一就是编程只能输出300行左右，远没有o3-mini编程长  
参考：[https://www.reddit.com/r/OpenAI/comments/1k1dtag/o4mini\_is\_unusable\_for\_coding/](https://www.reddit.com/r/OpenAI/comments/1k1dtag/o4mini_is_unusable_for_coding/)

  
**o3-mini**：api理论16k，![](https://cdn.linux.do/images/emoji/twemoji/cross_mark.png?v=14)
实际翻译8k(会缩写)，![](https://cdn.linux.do/images/emoji/twemoji/yellow_circle.png?v=14)
小说12k  
**o1-pro**：chat理论16k，![](https://cdn.linux.do/images/emoji/twemoji/white_check_mark.png?v=14)
实际研究12k。api$600/mt试不起不清楚  
**o1-preview**：api理论16k，![](https://cdn.linux.do/images/emoji/twemoji/cross_mark.png?v=14)
翻译拒绝，![](https://cdn.linux.do/images/emoji/twemoji/yellow_circle.png?v=14)
小说4k  
**o1-mini**：api理论16k，![](https://cdn.linux.do/images/emoji/twemoji/white_check_mark.png?v=14)
翻译16k，![](https://cdn.linux.do/images/emoji/twemoji/cross_mark.png?v=14)
小说2k  
**4.5**：api理论16k，照抄？k，翻译？k，![](https://cdn.linux.do/images/emoji/twemoji/cross_mark.png?v=14)
小说1.5k  
chat理论？k，照抄，翻译，小说  
**4.1**：api理论32k，![](https://cdn.linux.do/images/emoji/twemoji/cross_mark.png?v=14)
翻译拒绝，![](https://cdn.linux.do/images/emoji/twemoji/cross_mark.png?v=14)
小说2k  
**4.1-mini**：api理论32k，![](https://cdn.linux.do/images/emoji/twemoji/cross_mark.png?v=14)
翻译2k，![](https://cdn.linux.do/images/emoji/twemoji/cross_mark.png?v=14)
小说拒绝  
**4o-1120**：api理论16k，![](https://cdn.linux.do/images/emoji/twemoji/cross_mark.png?v=14)
照抄拒绝，![](https://cdn.linux.do/images/emoji/twemoji/cross_mark.png?v=14)
翻译拒绝，![](https://cdn.linux.do/images/emoji/twemoji/cross_mark.png?v=14)
小说1.5k  
**4o-mini**：api理论16k，![](https://cdn.linux.do/images/emoji/twemoji/cross_mark.png?v=14)
照抄拒绝，![](https://cdn.linux.do/images/emoji/twemoji/cross_mark.png?v=14)
小说1.5k

[](#p-5330324-h-7)有钢印但不严格的（照抄/翻译字多，自由发挥字少）
------------------------------------------

### [](#p-5330324-grok-8)Grok

字数统计准确率：50%  
**grok3**：![](https://cdn.linux.do/images/emoji/twemoji/white_check_mark.png?v=14)
api实际照抄20k(3w字)，![](https://cdn.linux.do/images/emoji/twemoji/yellow_circle.png?v=14)
翻译8k  
![](https://cdn.linux.do/images/emoji/twemoji/yellow_circle.png?v=14)
chat照抄10k，![](https://cdn.linux.do/images/emoji/twemoji/cross_mark.png?v=14)
小说2k  
**grok3r**：![](https://cdn.linux.do/images/emoji/twemoji/white_check_mark.png?v=14)
实际免费chat照抄19k字，![](https://cdn.linux.do/images/emoji/twemoji/cross_mark.png?v=14)
小说2k，无api  
**grok3-mini**：![](https://cdn.linux.do/images/emoji/twemoji/white_check_mark.png?v=14)
实际api照抄20k(3w字)，![](https://cdn.linux.do/images/emoji/twemoji/cross_mark.png?v=14)
翻译3k，![](https://cdn.linux.do/images/emoji/twemoji/cross_mark.png?v=14)
小说2k

### [](#p-5330324-deepseek-9)Deepseek

**r1**：api理论8k，![](https://cdn.linux.do/images/emoji/twemoji/yellow_circle.png?v=14)
实际OpenRouter免费照抄4k，![](https://cdn.linux.do/images/emoji/twemoji/cross_mark.png?v=14)
小说2k  
**ds3-0324**：api理论8k，![](https://cdn.linux.do/images/emoji/twemoji/yellow_circle.png?v=14)
实际OpenRouter免费照抄4k  
官网api理论8k，![](https://cdn.linux.do/images/emoji/twemoji/cross_mark.png?v=14)
照抄2k，![](https://cdn.linux.do/images/emoji/twemoji/yellow_circle.png?v=14)
小说3k

### [](#p-5330324-h-10)没有钢印的（照抄/翻译和自由发挥字都多）

### [](#p-5330324-gemini-11)Gemini

字数统计准确率：90%  
**2.5pro**：api理论64k，![](https://cdn.linux.do/images/emoji/twemoji/white_check_mark.png?v=14)
照抄64k，![](https://cdn.linux.do/images/emoji/twemoji/white_check_mark.png?v=14)
小说38k（要求每章4000字）  
**2.5pro Deep research**：chat15k，无api  
**2.5flash**：api理论40k，![](https://cdn.linux.do/images/emoji/twemoji/white_check_mark.png?v=14)
实际照抄40k，![](https://cdn.linux.do/images/emoji/twemoji/white_check_mark.png?v=14)
小说25k（要求每章3000字）  
**2.5flash-thinking**：api理论40k，![](https://cdn.linux.do/images/emoji/twemoji/white_check_mark.png?v=14)
实际照抄40k，![](https://cdn.linux.do/images/emoji/twemoji/white_check_mark.png?v=14)
小说26k（要求每章3000字）  
pro和flash的小说，要想字数多，不能直接要求总字数，而是应该要求每章字数  
例如总数要求1万，他生成12k  
但是直接要求2万字，他大概率说超过能力，不给生成  
如果要求每章3000字×10章，他会计算总字数3万，也可能拒绝生成  
如果要求每章3000字，不指定章节数，他一般就不会计算总字数，通常实际也会生成10章左右

### [](#p-5330324-claude-12)Claude

3.7：api理论64k，![](https://cdn.linux.do/images/emoji/twemoji/white_check_mark.png?v=14)
照抄64k，![](https://cdn.linux.do/images/emoji/twemoji/white_check_mark.png?v=14)
小说60k（要求每章6000，共10章）

[](#p-5330324-h-13)长文理解能力
-------------------------

大模型随着上下文增加，性能衰减也是很快的，只有o3和2.5pro能在120k保持90%的性能，2.5flash能达到75%，其他大多数模型在120k时只有40~60%的性能  
长文写作性能理论上也随写作长度衰减，因为大模型的原理就是每写一个token就要把前面提示词和输出全部重阅读一遍，再预测下一个token。  
阅读性能衰减慢的模型，在长文写作时，理论上写作性能衰减也慢  
来源：[Fiction.live](https://fiction.live/stories/Fiction-liveBench-Mar-25-2025/oQdzQvKHw8JyXbN87)

  

[![](https://cdn.ldstatic.com/optimized/4X/5/0/f/50f7d825b239fda43447fa486ee55c55aa303791_2_398x500.png)

微信图片\_20250422104717738×927 204 KB

](https://cdn.ldstatic.com/original/4X/5/0/f/50f7d825b239fda43447fa486ee55c55aa303791.png "微信图片_20250422104717")

[](#p-5330324-openai-14)为什么OpenAI的长文输出这么拉胯
------------------------------------------

我猜这不一定是技术问题，很可能是市场策略问题，  
例如o3 Deep research研究最多是60k，o3只有2k，显然不是技术问题，就是故意的  
OpenAI的80%的用户可能是在Chat端免费或包月，显然输出越少越好，因为成本低  
Gemini和Claude的80%用户在API，显然输出越多越好，因为输出越多收入越高  
这个看OpenRouter的API消耗排行就知道，前11名被claude，gemini，deepseek包揽，OpenAI用量最多的模型排在第12  

[![](https://cdn.ldstatic.com/optimized/4X/4/f/5/4f58f83f0a45fe519755c720d8bf38dbcc6e4ff2_2_529x500.png)

微信图片\_20250422125650770×727 84.7 KB

](https://cdn.ldstatic.com/original/4X/4/f/5/4f58f83f0a45fe519755c720d8bf38dbcc6e4ff2.png "微信图片_20250422125650")

  

![](https://cdn.linux.do/images/emoji/twemoji/heart.png?v=14)

heart

![](https://cdn.linux.do/images/emoji/twemoji/+1.png?v=14)

+1

34

​ ​ 回复

447 浏览量 42 赞 2 链接 21 用户

 [![](https://cdn.linux.do/user_avatar/linux.do/dwqxq1/96/412659_2.png)
 3](/u/dwqxq1 "dwqxq1") 

 [![](https://cdn.linux.do/letter_avatar/fengchris/96/5_d44a9b381edc88181525e3c8350177ca.png)
 3](/u/fengchris "fengchris") 

 [![](https://cdn.linux.do/user_avatar/linux.do/passerby/96/140633_2.png)](/u/passerby "passerby") 

 [![](https://cdn.linux.do/letter_avatar/tangdou/96/5_d44a9b381edc88181525e3c8350177ca.png)](/u/tangdou "tangdou") 

 [![](https://cdn.linux.do/user_avatar/linux.do/capgrey/96/471241_2.png)](/u/capgrey "capgrey") 

[![](https://cdn.linux.do/user_avatar/linux.do/dwqxq1/96/412659_2.png)
](/u/dwqxq1)

[dwqxq1](/u/dwqxq1)

活跃用户

1

[3 小时](/t/topic/585363/2?u=niyan2025 "发布日期")

持续更新中  
[@PSP](/u/psp)

  

1

​ ​ 回复

[![](https://cdn.linux.do/user_avatar/linux.do/6512345/96/516797_2.png)
](/u/6512345)

[65](/u/6512345)

[6512345](/u/6512345)なんでも知ってる

[3 小时](/t/topic/585363/3?u=niyan2025 "发布日期")

前排ww

  

​ ​ 回复

[![](https://cdn.linux.do/user_avatar/linux.do/buchilajiao/96/508963_2.png)
](/u/buchilajiao)

[buchilajiao](/u/buchilajiao)

[3 小时](/t/topic/585363/4?u=niyan2025 "发布日期")

前排，感谢大佬的测试分析

  

​ ​ 回复

[![](https://cdn.linux.do/user_avatar/linux.do/huanghun/96/546647_2.png)
](/u/huanghun)

[黄昏](/u/huanghun)

[huanghun](/u/huanghun)

[2 小时](/t/topic/585363/5?u=niyan2025 "发布日期")

感谢大佬辛苦测评

  

​ ​ 回复

[![](https://cdn.linux.do/user_avatar/linux.do/capgrey/96/471241_2.png)
](/u/capgrey)

[Grey](/u/capgrey)

[capgrey](/u/capgrey)浴火重生 ![](https://cdn.linux.do/images/emoji/twemoji/upside_down_face.png?v=14) 

[2 小时](/t/topic/585363/6?u=niyan2025 "发布日期")

做成表格会直观一点

  

​ ​ 回复

[![](https://cdn.linux.do/user_avatar/linux.do/wwow/96/545077_2.png)
](/u/wwow)

[樱悦](/u/wwow)

[wwow](/u/wwow)文化宣导员 ![](https://cdn.linux.do/images/emoji/twemoji/heartpulse.png?v=14) 

[2 小时](/t/topic/585363/7?u=niyan2025 "发布日期")

进来学习

  

​ ​ 回复

[![](https://cdn.linux.do/user_avatar/linux.do/shiki/96/98110_2.png)
](/u/shiki)

[神山识](/u/shiki)

[shiki](/u/shiki)一元复始 ![](https://cdn.linux.do/images/emoji/twemoji/books.png?v=14) 

[2 小时](/t/topic/585363/8?u=niyan2025 "发布日期")

感谢大佬测试

  

​ ​ 回复

[![](https://cdn.linux.do/user_avatar/linux.do/passerby/96/140633_2.png)
](/u/passerby)

[半杯无糖](/u/passerby)

[passerby](/u/passerby)大预言家 ![](https://cdn.linux.do/images/emoji/twemoji/fingerprint.png?v=14) 

[2 小时](/t/topic/585363/9?u=niyan2025 "发布日期")

非常详细的测试大佬![](https://cdn.linux.do/images/emoji/twemoji/ox.png?v=14)
![](https://cdn.linux.do/images/emoji/twemoji/beer_mug.png?v=14)

  

​ ​ 回复

[![](https://cdn.linux.do/letter_avatar/fengchris/96/5_d44a9b381edc88181525e3c8350177ca.png)
](/u/fengchris)

[fengchris](/u/fengchris)

[2 小时](/t/topic/585363/10?u=niyan2025 "发布日期")

还是比较符合实际情况的

gemini已经成了个人最好用的模型了 长上下文和长输出能力第一  
openai的模型总爱偷懒 让他输出他偏不 只有o3 deeprearch才能满血输出

  

1 个回复

1

​ ​ 回复

[![](https://cdn.linux.do/user_avatar/linux.do/slashkkk/96/311558_2.png)
](/u/slashkkk)

[空气动力学](/u/slashkkk)

[slashkkk](/u/slashkkk)指导顾问 ![](https://cdn.ldstatic.com/original/3X/4/9/494acbbf0289fd91fc9c693d162d94e603df6f1b.png?v=14) 

[2 小时](/t/topic/585363/11?u=niyan2025 "发布日期")

学习了。大佬的文章没起必研的。  
顺带请教一个问题，如果宣称的max\_output\_tokens少于实际，能否通过调整参数来实现最大输出呢？

  

​ ​ 回复

[![](https://cdn.linux.do/user_avatar/linux.do/biss/96/451232_2.png)
](/u/Biss)

[donk666](/u/Biss)

[Biss](/u/Biss)

[2 小时](/t/topic/585363/13?u=niyan2025 "发布日期")

web端o3的单次输出的确显著少于o1，不知道后面会不会再调整

  

1

​ ​ 回复

[![](https://cdn.linux.do/user_avatar/linux.do/garywu/96/472934_2.png)
](/u/garywu)

[garywu](/u/garywu)

[2 小时](/t/topic/585363/14?u=niyan2025 "发布日期")

感谢大佬的测试

  

​ ​ 回复

[![](https://cdn.linux.do/user_avatar/linux.do/edwinchenc/96/519543_2.png)
](/u/EDWINCHENC)

[CHEN](/u/EDWINCHENC)

[EDWINCHENC](/u/EDWINCHENC)种子用户 ![](https://cdn.ldstatic.com/original/3X/2/6/2661bab59c544650fe3997aea16448f188e5cc08.png?v=14) 

[2 小时](/t/topic/585363/15?u=niyan2025 "发布日期")

GPT真拉跨啊

  

​ ​ 回复

[![](https://cdn.linux.do/user_avatar/linux.do/henrylol/96/295285_2.png)
](/u/Henrylol)

[Henrylol](/u/Henrylol)

[1 小时](/t/topic/585363/16?u=niyan2025 "发布日期")

OpenAI真的捞啊 ![](https://cdn.linux.do/images/emoji/twemoji/zany_face.png?v=14)
  
Gemini生成长文本，感觉还会很积极的多写点

  

1

​ ​ 回复

[![](https://cdn.linux.do/user_avatar/linux.do/kobayashikanna/96/384876_2.png)
](/u/KobayashiKanna)

[小林康娜](/u/KobayashiKanna)

[KobayashiKanna](/u/KobayashiKanna)

[1 小时](/t/topic/585363/17?u=niyan2025 "发布日期")

来看看实测

  

​ ​ 回复

[![](https://cdn.linux.do/letter_avatar/cat3399/96/5_d44a9b381edc88181525e3c8350177ca.png)
](/u/cat3399)

[cat3399](/u/cat3399)

活跃用户 ![](https://cdn.linux.do/images/emoji/twemoji/speech_balloon.png?v=14) 

[1 小时](/t/topic/585363/18?u=niyan2025 "发布日期")

感谢大佬详细的测试,我昨天也在测试这个,论长输出还是得gemini,grok3mini照抄可以输出30k  

[![](https://cdn.ldstatic.com/original/4X/f/7/0/f708c1168ac8d7cee261943a5f3466dee289bb9b.png)

image433×131 2.08 KB

](https://cdn.ldstatic.com/original/4X/f/7/0/f708c1168ac8d7cee261943a5f3466dee289bb9b.png "image")

  
但是让他翻译就拉稀了

  

2

​ ​ 回复

[![](https://cdn.linux.do/user_avatar/linux.do/psp/96/580267_2.png)
](/u/PSP)

[PSP](/u/PSP)

1

[1 小时](/t/topic/585363/19?u=niyan2025 "发布日期")

我的提示词，长文输出测试排名（只计算正文，含难度）。

o3 （Deep research）  
Gemini 2.5 Pro：38K的最长长度，遥遥领先所有模型，但是需要特定提示词，否则达不到字数  
Claude 3.7 Sonnet-thinking：长度不如gemini，但是拒绝度较低  
Gemini 2.5 Flash-thinking  
o1 ：最容易  
o3 mini，o1 mini：较容易  
Gemini 2.0 Flash-thinking（0121）  
Grok 3-mini  
o3，o4 mini  
Gemini 2.0 Flash-thinking（1219）  
Gemini 2.0 Pro-1206  
Grok 3  
GPT-4o  
Deepseek R1，QWQ-32B

  

1

​ ​ 回复

[![](https://cdn.linux.do/letter_avatar/tangdou/96/5_d44a9b381edc88181525e3c8350177ca.png)
](/u/tangdou)

[tangdou](/u/tangdou)

 ![](https://cdn.linux.do/letter_avatar/fengchris/48/5_d44a9b381edc88181525e3c8350177ca.png)
 fengchris

[1 小时](/t/topic/585363/20?u=niyan2025 "发布日期")

OpenAI 降智好恶心，gemini 大善人都免费用还不限量

  

​ ​ 回复

[![](https://cdn.linux.do/letter_avatar/naroo/96/5_d44a9b381edc88181525e3c8350177ca.png)
](/u/NAROO)

[NAROO](/u/NAROO)

[1 小时](/t/topic/585363/21?u=niyan2025 "发布日期")

o3长文那么强吗？  
实测最近2.5pro降智越来越厉害，我使用api对话，在一个已经有9W token的对话里，发给它400K不到的文本，多次测试都答复只阅读了1/4到1/3，说看不到后面的内容，不知道是怎么回事。

  

1 个回复

​ ​ 回复

Invalid date Invalid date

Settings
========

🏷️ UTags - Add usertags to links

Other Extensions
----------------

[🔗 Links Helper](https://greasyfork.org/en/scripts/464541-links-helper)

[V2EX.REP - 专注提升 V2EX 主题回复浏览体验](https://greasyfork.org/en/scripts/466589-v2ex-rep-%E4%B8%93%E6%B3%A8%E6%8F%90%E5%8D%87-v2ex-%E4%B8%BB%E9%A2%98%E5%9B%9E%E5%A4%8D%E6%B5%8F%E8%A7%88%E4%BD%93%E9%AA%8C)

[v2ex.min - V2EX Minimalist (极简风格)](https://greasyfork.org/en/scripts/463552-v2ex-min-v2ex-%E6%9E%81%E7%AE%80%E9%A3%8E%E6%A0%BC)

[Replace Ugly Avatars](https://greasyfork.org/en/scripts/472616-replace-ugly-avatars)

↑↓⇔⇧⇩